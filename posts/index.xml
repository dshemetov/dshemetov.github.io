<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Something Darker</title><link>https://dshemetov.github.io/posts/</link><description>Something Darker (Posts)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 12 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://dshemetov.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Installs for the Scan Statistics for Network Epidemics Project</title><link>https://dshemetov.github.io/posts/scan-statistics-installs/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><guid>https://dshemetov.github.io/posts/scan-statistics-installs/</guid><description>&lt;p>I’m going to go from scratch, assuming you’re on Mac OS X.&lt;/p>
&lt;h2 id="install-pyenv-and-virtualenv" >Install pyenv and virtualenv
&lt;span>
&lt;a href="#install-pyenv-and-virtualenv">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>This will manage your python installations.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>brew install pyenv pyenv-virtualenv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Install your desired python, which in this case is 3.7.3.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>pyenv install 3.7.3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now navigate to your directory and create a new virtualenv for this directory.&lt;/p>
&lt;pre tabindex="0">&lt;code>pyenv virtualenv network_analysis
&lt;/code>&lt;/pre>&lt;p>For future reference:&lt;/p>
&lt;ul>
&lt;li>pyenv stores its virtualenvs in: &lt;code>/.pyenv/versions/&lt;/code>&lt;/li>
&lt;li>pipenv stores them in: &lt;code>/.local/share/&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="install-the-basics" >Install the basics
&lt;span>
&lt;a href="#install-the-basics">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>pip install numpy ipykernel scipy matplotlib scikit-learn networkx seaborn xlrd pillow blackcellmagic joblib netwulf pycodestyle
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="install-basemap" >Install basemap
&lt;span>
&lt;a href="#install-basemap">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Warning: large download (80MBs).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>pip install git+https://github.com/matplotlib/basemap.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="install-eon" >Install EoN
&lt;span>
&lt;a href="#install-eon">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>You need to get the 1.0.9rc1 version or older, which wasn’t on PyPi.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>pip install git+https://github.com/springer-math/Mathematics-of-Epidemics-on-Networks.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="install-this-virtualenv-as-an-ipython-kernel-in-your-assumed-existing-jupyter-installation" >Install this virtualenv as an IPython kernel in your (assumed existing) Jupyter installation
&lt;span>
&lt;a href="#install-this-virtualenv-as-an-ipython-kernel-in-your-assumed-existing-jupyter-installation">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>python -m ipykernel install --user --name&lt;span style="color:#f92672">=&lt;/span>network_analysis
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="install-graph-tool-on-os-x-with-pipenv" >Install graph-tool on OS X with pipenv
&lt;span>
&lt;a href="#install-graph-tool-on-os-x-with-pipenv">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>First install it on your machine using Brew (pip is unfortunately not available here, because graph-tool is a hybrid C++/Python package).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>brew install graph-tool
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now this will install graph-tool into a Python that Brew deems best. Make sure that this is the same version as the one in your virtual-env.&lt;/p>
&lt;p>Next, we will want to symlink the graph-tool installation into your virtual-env installation (yes, this is awful and completely defeats the purpose of using pipenv, but these are the wonders of dev code without which life would be so much less fun :|). Use the directories here for a hint of where to go for the right directories (use pipenv &amp;ndash;venv to find the virtual env directory).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>ln -s /usr/local/Cellar/graph-tool/2.29/lib/python3.7/site-packages/graph_tool/ ~/.pyenv/versions/network_analysis/lib/python3.7/site-packages
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We also need pycairo for drawing (comes with the brew installation).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>ln -s /usr/local/Cellar/py3cairo/1.18.1/lib/python3.7/site-packages/cairo/ ~/.pyenv/versions/network_analysis/lib/python3.7/site-packages
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Binomial Limit to the Poisson</title><link>https://dshemetov.github.io/posts/binomial-poisson/</link><pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate><guid>https://dshemetov.github.io/posts/binomial-poisson/</guid><description>&lt;p>A sequence of Binomial distributions $\text{Bi}(n, \frac \lambda n)$ limits to the Poisson distribution $\text{Po}(\lambda)$ as $n \to \infty$.
As is often the case in probability, you can show this with generating functions.
Here, however, we will show the pointwise limit of distributions.&lt;/p>
&lt;p>We want to show that for a fixed $k$
$$
\lim_{n \to \infty} \underbrace{{n \choose k} \left(\frac \lambda n \right)^k \left(1 - \frac \lambda n \right)^{n-k}}_{\text{Binomial pmf}} = \underbrace{e^{-\lambda} \frac{\lambda^k}{k!}}_{\text{Poisson pmf}}
$$&lt;/p>
&lt;p>We will show that&lt;/p>
&lt;p>\begin{align}
{n \choose k} \frac 1 {n^k} &amp;amp; \to \frac 1 {k!} \\
\lambda^k \left(1 - \frac \lambda n \right)^{n-k} &amp;amp; \to e^{-\lambda} \lambda^k
\end{align}&lt;/p>
&lt;p>The second limit follows straight from a definition of $e$
$$
\lim_{n \to \infty} \left(1 + \frac \lambda n \right)^n = e^{\lambda},
$$
which in itself can be shown by taking logs, Taylor expanding, and relying on the continuity of $e^x$: $n \log \left(1 + \frac \lambda n \right) = n \left( \frac \lambda n + O\left(\frac \lambda n\right)^2 \right) \to \lambda.$&lt;/p>
&lt;p>The first limit can be shown by a laborious Stirling&amp;rsquo;s approximation, but it is really enough to note the following&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>
$$
1 = \frac{n^k}{n^k} \geq \frac{ n^{(k)} } { n^k } \geq \frac{(n-k+1)^k}{n^k} \overset{n \to \infty}{\to} 1.
$$&lt;/p>
&lt;h1 id="encore-deriving-stirlings-formula" >Encore: Deriving Stirling&amp;rsquo;s Formula
&lt;span>
&lt;a href="#encore-deriving-stirlings-formula">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h1>&lt;p>How do we derive Stirling&amp;rsquo;s formula though? I used it maybe twenty times before I realized I had never seen a proof. Here&amp;rsquo;s a sketch of the important pieces.&lt;/p>
&lt;p>\begin{align}
n! &amp;amp; = \int_0^\infty x^n e^{-x} dx &amp;amp; \text{(Definition)} \\
&amp;amp; = \int_0^\infty e^{n \ln n -x} dx &amp;amp; \text{(Algebra)} \\
&amp;amp; = e^{n \ln n } n \int_0^\infty e^{n(\ln y - y)} dy &amp;amp; \text{(Change of Variables)} \\
&amp;amp; \sim \sqrt{\frac{2\pi} n} e^{-n} n e^{n \ln n} &amp;amp; \text{(Laplace&amp;rsquo;s Method)}
\end{align}&lt;/p>
&lt;p>&lt;strong>Theorem 1:&lt;/strong> [Laplace&amp;rsquo;s Method]
Suppose $f(x)$ is twice differentiable on $[a,b]$ and $\exists !x$ such that $f(x_0) = \max_{[a,b]} f(x)$ and $f&amp;rsquo;&amp;rsquo;(x_0)&amp;lt;0$, then as $n \to \infty$
$$
\int_a^b e^{nf(x)} dx \sim e^{nf(x_0)} \sqrt{\frac{2\pi}{-nf&amp;rsquo;&amp;rsquo;(x_0)}}
$$&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Here we use the &lt;em>factorial power&lt;/em> notation $n^{(k)} \coloneqq n (n-1) \dots (n-(k-1)) = \frac{n!}{(n-k)!}$.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Compressed Statistics Notes I</title><link>https://dshemetov.github.io/posts/compressed-stats-notes-1/</link><pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate><guid>https://dshemetov.github.io/posts/compressed-stats-notes-1/</guid><description>&lt;p>[Attention conservation: this is ]&lt;/p>
&lt;p>I ran some numerical simulations and obtained some complicated results. Just want to get this out there.&lt;/p>
&lt;p>So a recap of the question: given a 5-ary channel, our building blocks for reasonable channels are the threshold channels $V_i$, where we send a one if we see $\geq i$ ones. In the 3-ary channel case, there was no question about how to mix $V_2$ and $V_3$ to obtain channels that distinguish arbitrary hypotheses split over $p_0$ in $(\frac 1 2, 1)$. However, in the 5-ary case, we need to decide how to select an affine mixture $(\alpha_1, \alpha_2, \alpha_3)$, where $\sum_i \alpha_i = 1$, so that $\alpha_1 V_3 + \alpha_2 V_4 + \alpha_3 V_5$ maximizes the separation of the hypotheses (which we currently measure as maximizing the convergence rate to a single fixed point).&lt;/p>
&lt;p>How do we choose this channel? Well, our heuristic currently is that the one with the maximal derivative at the fixed point maximizes the convergence rate (when I ran numerical tests to find the empirical convergence rate to an epsilon neighborhood of the iterated function, I got results that supported this heuristic). So we should maximized the derivative at the fixed point.&lt;/p>
&lt;p>By the fixed point constraint $\alpha_1 V_3(p) + \alpha_2 V_4(p) + \alpha_3 V_5(p)=p$, whose solution we will call $p_0$, we reduce one of the parameters. We then maximize the derivative $\frac d{dp} \alpha_1 V_3(p) + \alpha_2 V_4(p) + \alpha_3 V_5(p) |_{p=p_0}$, which in this case is a 1-dimensional maximization. The result I get is not a simple one. It turns out that there is a transition point, where if the fixed point $p_0$ is on one side, it is optimal to use $\alpha_1 V_3 + \alpha_2 V_4$ (no $V_5$, with $\alpha_1,\alpha_2$ of course depending on the fixed point) and on the other side it&amp;rsquo;s optimal to use $\alpha_2 V_4 + \alpha_3 V_5$. The transition occurs somewhere between $\frac 6 7$ and $\frac 7 8$.&lt;/p>
&lt;p>My thoughts:&lt;/p>
&lt;ol>
&lt;li>I could pin down that transition point exactly, but I’m not sure that it’s that important. The 5-ary case suggests that the result will be a somewhat complicated piecewise-linear function.&lt;/li>
&lt;li>This method is going to get harder on 7-ary and larger channels; the optimization might still be analyzable; it is a $\lfloor \frac{m-3}2 \rfloor$-dimensional optimization of the form&lt;/li>
&lt;/ol>
&lt;p>\begin{align}
\max_{\vec \alpha} &amp;amp; \sum_{i=\lfloor \frac {n+1} 2 \rfloor}^n \alpha_i V_i’(p_0) \
\text{s.t} &amp;amp; \sum_i \alpha_i = 1 \
&amp;amp; \sum_i \alpha_i V_i(p_0) = p_0.
\end{align}&lt;/p></description></item></channel></rss>