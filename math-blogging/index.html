<!doctype html><html lang=en-us><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Math Blogging | Dmitry's Very Online Internet Webpage Site</title><meta name=title content="Math Blogging"><meta name=description content="A few cute derivations to test math blogging with Hugo.
Binomial Limit to Poisson
A basic fact about Binomial distributions is that they can be approximated by the Poisson distribution in a certain limit.
As is often the case in probability, you can show this with generating functions.
Here, however, we will show the pointwise limit of distributions.
First, let us recall a few definitions.
The Binomial variable $\text{Bi}(n, \frac \lambda n)$ has the probability mass function (pmf)"><meta name=keywords content="math,blogging,hugo,"><meta property="og:url" content="https://dshemetov.github.io/math-blogging/"><meta property="og:site_name" content="Dmitry's Very Online Internet Webpage Site"><meta property="og:title" content="Math Blogging"><meta property="og:description" content="A few cute derivations to test math blogging with Hugo.
Binomial Limit to Poisson A basic fact about Binomial distributions is that they can be approximated by the Poisson distribution in a certain limit. As is often the case in probability, you can show this with generating functions. Here, however, we will show the pointwise limit of distributions.
First, let us recall a few definitions. The Binomial variable $\text{Bi}(n, \frac \lambda n)$ has the probability mass function (pmf)"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2019-11-07T00:00:00+00:00"><meta property="article:modified_time" content="2019-11-07T00:00:00+00:00"><meta property="article:tag" content="Math"><meta property="article:tag" content="Blogging"><meta property="article:tag" content="Hugo"><meta name=twitter:card content="summary"><meta name=twitter:title content="Math Blogging"><meta name=twitter:description content="A few cute derivations to test math blogging with Hugo.
Binomial Limit to Poisson A basic fact about Binomial distributions is that they can be approximated by the Poisson distribution in a certain limit. As is often the case in probability, you can show this with generating functions. Here, however, we will show the pointwise limit of distributions.
First, let us recall a few definitions. The Binomial variable $\text{Bi}(n, \frac \lambda n)$ has the probability mass function (pmf)"><meta itemprop=name content="Math Blogging"><meta itemprop=description content="A few cute derivations to test math blogging with Hugo.
Binomial Limit to Poisson A basic fact about Binomial distributions is that they can be approximated by the Poisson distribution in a certain limit. As is often the case in probability, you can show this with generating functions. Here, however, we will show the pointwise limit of distributions.
First, let us recall a few definitions. The Binomial variable $\text{Bi}(n, \frac \lambda n)$ has the probability mass function (pmf)"><meta itemprop=datePublished content="2019-11-07T00:00:00+00:00"><meta itemprop=dateModified content="2019-11-07T00:00:00+00:00"><meta itemprop=wordCount content="593"><meta itemprop=keywords content="Math,Blogging,Hugo"><meta name=referrer content="no-referrer-when-downgrade"><style>:root{--width:720px;--font-main:Verdana, sans-serif;--font-secondary:Verdana, sans-serif;--font-scale:1em;--background-color:#fff;--heading-color:#222;--text-color:#444;--link-color:#3273dc;--visited-color:#8b6fcb;--blockquote-color:#222}@media(prefers-color-scheme:dark){:root{--background-color:#01242e;--heading-color:#eee;--text-color:#ddd;--link-color:#8cc2dd;--visited-color:#8b6fcb;--blockquote-color:#ccc}}body{font-family:var(--font-secondary);font-size:var(--font-scale);margin:auto;padding:20px;max-width:var(--width);text-align:left;background-color:var(--background-color);word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:var(--text-color)}h1,h2,h3,h4,h5,h6{font-family:var(--font-main);color:var(--heading-color)}a{color:var(--link-color);cursor:pointer;text-decoration:none}a:hover{text-decoration:underline}nav a{margin-right:8px}strong,b{color:var(--heading-color)}button{margin:0;cursor:pointer}time{font-family:monospace;font-style:normal;font-size:15px}main{line-height:1.6}table{width:100%}hr{border:0;border-top:1px dashed}img{max-width:100%}code{font-family:monospace;padding:2px;border-radius:3px}blockquote{border-left:1px solid #999;color:var(--blockquote-color);padding-left:20px;font-style:italic}footer{padding:25px 0;text-align:center}.title:hover{text-decoration:none}.title h1{font-size:1.5em}.inline{width:auto!important}.highlight,.code{border-radius:3px;margin-block-start:1em;margin-block-end:1em;overflow-x:auto}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:var(--visited-color)}</style><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={loader:{load:["[tex]/mathtools"]},tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,macros:{R:"{\\mathbb R}",Z:"{\\mathbb Z}",C:"{\\mathbb C}"},packages:{"[+]":["mathtools"]}},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><style type=text/css>@media(prefers-color-scheme:dark){body{background-color:#1a2638}code{background-color:#222;color:#eba613}}a{text-decoration:none}a:hover{text-decoration:underline}ol li{counter-increment:listCounter}ol li::marker{content:'(' counter(listCounter)").  "}figure{text-align:center;font-style:italic;font-size:smaller;text-indent:0;display:block;margin-left:auto;margin-right:auto;max-width:75%}figure.left{float:left;margin-right:2em;max-width:75%}figure.right{float:right;margin-left:2em;max-width:75%}@media(max-width:800px){figure.left,figure.right{float:none;margin-top:2em;margin-bottom:2em;margin-right:2em;margin-left:2em;max-width:50%}}.common-footer{margin-top:1em;padding-top:1em}.content{margin-top:1em}code.has-jax{-webkit-font-smoothing:antialiased;background:inherit!important;border:none!important;font-size:100%}</style><meta property="og:type" content="website"><meta property="og:url" content><meta property="og:title" content><meta property="og:description" content><meta property="og:image" content><meta name=description content="A few cute derivations to test math blogging with Hugo.
Binomial Limit to Poisson
A basic fact about Binomial distributions is that they can be approximated by the Poisson distribution in a certain limit.
As is often the case in probability, you can show this with generating functions.
Here, however, we will show the pointwise limit of distributions.
First, let us recall a few definitions.
The Binomial variable $\text{Bi}(n, \frac \lambda n)$ has the probability mass function (pmf)"></head><body><header><a href=/ class=title><h2>Dmitry's Very Online Internet Webpage Site</h2></a><nav><a href=/>Home</a>
<a href=/now/>Now</a>
<a href=/projects/>Projects</a>
<a href=/blog/>Blog</a></nav></header><main><h1>Math Blogging</h1><p><i><time datetime=2019-11-07>2019-11-07</time></i></p><content><p>A few cute derivations to test math blogging with <a href=https://gohugo.io>Hugo</a>.</p><h2 id=binomial-limit-to-poisson>Binomial Limit to Poisson</h2><p>A basic fact about Binomial distributions is that they can be approximated by the Poisson distribution in a certain limit.
As is often the case in probability, you can show this with generating functions.
Here, however, we will show the pointwise limit of distributions.</p><p>First, let us recall a few definitions.
The Binomial variable $\text{Bi}(n, \frac \lambda n)$ has the probability mass function (pmf)</p>$$
p_B\left(k; n, \frac \lambda n \right) = {n \choose k} \left(\frac \lambda n \right)^k \left(1 - \frac \lambda n \right)^{n-k},
$$<p>while the Poisson variable $\text{Po}(\lambda)$ has the pmf</p>$$
p_P (k; \lambda ) = e^{-\lambda} \frac{\lambda^k}{k!}.
$$<p><strong>Theorem 1:</strong> The sequence of random variables $\{ X_n \}_{i=1}^\infty$ with $X_n \sim \text{Bi}(n, \frac \lambda n)$ limits in distribution to $\text{Po}(\lambda)$ as $n \to \infty$.</p><p><em>Proof:</em> We want to show that for a fixed $k$</p>$$
\lim_{n \to \infty} \underbrace{{n \choose k} \left(\frac \lambda n \right)^k \left(1 - \frac \lambda n \right)^{n-k}}\_{\text{Binomial pmf}} = \underbrace{e^{-\lambda} \frac{\lambda^k}{k!}}\_{\text{Poisson pmf}}
$$<p>The limit</p>$$
\lambda^k \left(1 - \frac \lambda n \right)^{n-k} \to e^{-\lambda} \lambda^k
$$<p>follows straight from one of the definitions of $e$<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p>$$
\lim_{n \to \infty} \left(1 + \frac \lambda n \right)^n = e^{\lambda}.
$$<p>The limit</p>$$
{n \choose k} \frac 1 {n^k} \to \frac 1 {k!}
$$<p>can be shown by a laborious Stirling&rsquo;s approximation, but it is really enough to note the following<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p>$$
1 = \frac{n^k}{n^k} \geq \frac{ n^{\underline k} } { n^k } \geq \frac{(n-k+1)^k}{n^k} \overset{n \to \infty}{\to} 1.
$$<p>Putting the two limits together gives us our result. $\Box$</p><h2 id=deriving-stirlings-formula>Deriving Stirling&rsquo;s Formula</h2><p>So I&rsquo;ve used <a href=https://en.wikipedia.org/wiki/Stirling%27s_approximation>Stirling&rsquo;s formula</a> maybe twenty times, but now I realize I&rsquo;ve never seen a proof.
How do we derive it though?</p><p><strong>Theorem 2:</strong> We have that $n! \sim \sqrt{2\pi n} \left( \frac n e \right)^n$ asymptotically (the ratio tends to 1 as $n \to \infty$).</p><p><em>Proof sketch:</em></p><p>\begin{align}
n! & = \int_0^\infty x^n e^{-x} dx & \tag{Definition} \\
& = \int_0^\infty e^{n \ln x - x} dx & \tag{Algebra} \\
& = e^{n \ln n} n \int_0^\infty e^{n (\ln y - x)} dy & \tag{Change of Variables} \\
& \sim \sqrt{\frac{2\pi} n} e^{-n} n e^{n \ln n} & \tag{Laplace&rsquo;s Method}
\end{align}</p><p>This gives us the relation we want $\Box$.</p><p>Laplace&rsquo;s method refers to the following statement.</p><p><strong>Theorem 3:</strong> Suppose that:</p><ul><li>$f: [a, b] \to \R$ is twice differentiable on $[a,b]$</li><li>$f(x)$ attains a unique maximum on $[a, b]$ at $x_0$</li><li>$f&rsquo;&rsquo;(x_0)&lt;0$.</li></ul><p>Then</p>$$
\int_a^b e^{nf(x)} dx \sim e^{nf(x_0)} \sqrt{\frac{2\pi}{-nf''(x_0)}}
$$<p>as $n \to \infty$.</p><p>We will not prove this one, but refer you <a href=https://en.wikipedia.org/wiki/Laplace%27s_method#Formal_statement_and_proof>here</a>.<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></p><p>A few more Stirling approximation facts:</p><ul><li>you can get even more terms in the asymptotic expansion<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> by using the <a href=https://en.wikipedia.org/wiki/Euler%E2%80%93Maclaurin_formula>Euler-Maclaurin formula</a>,</li><li>a simple bound of $\sqrt{2\pi n} \left( \frac n e \right)^n e^{\frac 1 {12n + 1}} &lt; n! &lt; \sqrt{2\pi n} \left( \frac n e \right)^n e^{\frac 1 {12n}}$ is available due to <a href=https://www.jstor.org/stable/2308012>Robbins</a>.</li></ul><figure><img src=/images/pumps2019.jpg alt="A bonus test picture." width=600px height=400px><figcaption><p>A bonus test picture.</p></figcaption></figure><h2 id=footnotes>Footnotes</h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>One way to show this definition is to take logs, Taylor expand, and rely on the continuity of $e^x$:</p>$$n \log \left(1 + \frac \lambda n \right) = n \left( \frac \lambda n + O\left(\frac \lambda n\right)^2 \right) \to \lambda.$$&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></li><li id=fn:2><p>Here we use the <em><a href=https://en.wikipedia.org/wiki/Falling_and_rising_factorials>falling factorial</a></em> notation:</p>$$n^{\underline k} \coloneqq n (n-1) \cdots (n-(k-1)) = \frac{n!}{(n-k)!}.$$&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></li><li id=fn:3><p>By the way, <a href=https://michelf.ca/projects/php-markdown/extra/#footnotes>footnotes can be multi-line</a>.
For more information on the Markdown parser used by hugo, see the <a href=https://github.com/yuin/goldmark>Goldmark repo</a>.
<a href=https://gohugo.io/getting-started/configuration-markup>Here</a> are the default settings used by Hugo.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p><a href=https://dlmf.nist.gov/>NIST DLMF</a> is a useful reference for <a href=https://en.wikipedia.org/wiki/Asymptotic_expansion>asymptotic expansion</a> (see e.g. the Gamma function chapter).&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></content><p><a href=https://dshemetov.github.io/blog/math/>#Math</a>
<a href=https://dshemetov.github.io/blog/blogging/>#Blogging</a>
<a href=https://dshemetov.github.io/blog/hugo/>#Hugo</a></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>